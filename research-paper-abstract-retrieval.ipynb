{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How to Build a RAG-Powered Chatbot with Chat, Embed, and Rerank","metadata":{"id":"jKhcTYOEZy68"}},{"cell_type":"markdown","source":"*Read the accompanying [blog post here](https://txt.cohere.com/rag-chatbot).*","metadata":{"id":"StIYkOqgZy7D"}},{"cell_type":"markdown","source":"![Feature](https://github.com/cohere-ai/notebooks/blob/main/notebooks/images/rag-chatbot.png?raw=1)","metadata":{"id":"LznZvRyYZy7E"}},{"cell_type":"markdown","source":"In this notebook, you’ll learn how to build a chatbot that has RAG capabilities, enabling it to connect to external documents, ground its responses on these documents, and produce document citations in its responses.","metadata":{"id":"lI8ZLnfIZy7F"}},{"cell_type":"markdown","source":"Below is a diagram that provides an overview of what we’ll build, followed by a list of the key steps involved.\n\n![Overview](https://github.com/cohere-ai/notebooks/blob/main/notebooks/images/rag-chatbot-flow.png?raw=1)","metadata":{"id":"hSFxwSchZy7G"}},{"cell_type":"markdown","source":"Setup phase:\n- Step 0: Ingest the documents – get documents, chunk, embed, and index.\n\nFor each user-chatbot interaction:\n- Step 1: Get the user message\n- Step 2: Call the Chat endpoint in query-generation mode\n- If at least one query is generated\n    - Step 3: Retrieve and rerank relevant documents\n    - Step 4: Call the Chat endpoint in document mode to generate a grounded response with citations\n- If no query is generated\n    - Step 4: Call the Chat endpoint in normal mode to generate a response\n\nThroughout the conversation:\n- Append the user-chatbot interaction to the conversation thread\n- Repeat with every interaction","metadata":{"id":"7Tb0CIxKZy7H"}},{"cell_type":"code","source":"! pip install cohere hnswlib unstructured -q","metadata":{"id":"LmiKzBelZy7I","execution":{"iopub.status.busy":"2023-11-26T20:48:32.879413Z","iopub.execute_input":"2023-11-26T20:48:32.880398Z","iopub.status.idle":"2023-11-26T20:48:45.321633Z","shell.execute_reply.started":"2023-11-26T20:48:32.880363Z","shell.execute_reply":"2023-11-26T20:48:45.320248Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"! pip install openai tiktoken","metadata":{"id":"M0eQRUjtBFVI","outputId":"bb1c9618-480e-488b-afd8-91aac30a70ae","execution":{"iopub.status.busy":"2023-11-26T20:48:53.311405Z","iopub.execute_input":"2023-11-26T20:48:53.312305Z","iopub.status.idle":"2023-11-26T20:49:05.506133Z","shell.execute_reply.started":"2023-11-26T20:48:53.312265Z","shell.execute_reply":"2023-11-26T20:49:05.504971Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.3.5)\nRequirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.5.1)\nRequirement already satisfied: anyio<4,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.8.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.25.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.10.12)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\nRequirement already satisfied: typing-extensions<5,>=4.5 in /opt/conda/lib/python3.10/site-packages (from openai) (4.5.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.8.8)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n","output_type":"stream"}]},{"cell_type":"code","source":"import cohere\nimport os\nimport hnswlib\nimport json\nimport uuid\nfrom typing import List, Dict\nfrom unstructured.partition.html import partition_html\nfrom unstructured.chunking.title import chunk_by_title\n\nos.environ[\"COHERE_API_KEY\"]= \"vOXc8PMABEh4ZgaSmxiirTsGom3Ttq482wdMmYBC\"\n\nco = cohere.Client(os.environ[\"COHERE_API_KEY\"])","metadata":{"id":"URegRtxVZy7L","execution":{"iopub.status.busy":"2023-11-26T20:49:07.661445Z","iopub.execute_input":"2023-11-26T20:49:07.661868Z","iopub.status.idle":"2023-11-26T20:49:07.668402Z","shell.execute_reply.started":"2023-11-26T20:49:07.661832Z","shell.execute_reply":"2023-11-26T20:49:07.667515Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#@title Enable text wrapping in Google colab\n\nfrom IPython.display import HTML, display\n\ndef set_css():\n  display(HTML('''\n  <style>\n    pre {\n        white-space: pre-wrap;\n    }\n  </style>\n  '''))\nget_ipython().events.register('pre_run_cell', set_css)","metadata":{"id":"0K4K0d7YZy7M","execution":{"iopub.status.busy":"2023-11-26T20:49:10.192165Z","iopub.execute_input":"2023-11-26T20:49:10.192977Z","iopub.status.idle":"2023-11-26T20:49:10.198555Z","shell.execute_reply.started":"2023-11-26T20:49:10.192942Z","shell.execute_reply":"2023-11-26T20:49:10.197562Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Documents component","metadata":{"id":"kCBp9XB8Zy7N"}},{"cell_type":"code","source":"class Documents:\n    \"\"\"\n    A class representing a collection of documents.\n\n    Parameters:\n    sources (list): A list of dictionaries representing the sources of the documents. Each dictionary should have 'title' and 'url' keys.\n\n    Attributes:\n    sources (list): A list of dictionaries representing the sources of the documents.\n    docs (list): A list of dictionaries representing the documents, with 'title', 'content', and 'url' keys.\n    docs_embs (list): A list of the associated embeddings for the documents.\n    retrieve_top_k (int): The number of documents to retrieve during search.\n    rerank_top_k (int): The number of documents to rerank after retrieval.\n    docs_len (int): The number of documents in the collection.\n    index (hnswlib.Index): The index used for document retrieval.\n\n    Methods:\n    load(): Loads the data from the sources and partitions the HTML content into chunks.\n    embed(): Embeds the documents using the Cohere API.\n    index(): Indexes the documents for efficient retrieval.\n    retrieve(query): Retrieves documents based on the given query.\n\n    \"\"\"\n\n    def __init__(self, sources: List[Dict[str, str]]):\n        self.sources = sources\n        self.docs = []\n        self.docs_embs = []\n        self.retrieve_top_k = 10\n        self.rerank_top_k = 3\n        self.load()\n        self.embed()\n        self.index()\n\n    def load(self) -> None:\n        \"\"\"\n        Loads the documents from the sources and chunks the HTML content.\n        \"\"\"\n        print(\"Loading documents...\")\n\n        for source in self.sources:\n            elements = partition_html(url=source[\"url\"])\n            chunks = chunk_by_title(elements)\n            for chunk in chunks:\n                self.docs.append(\n                    {\n                        \"title\": source[\"title\"],\n                        \"text\": str(chunk),\n                        \"url\": source[\"url\"],\n                    }\n                )\n\n    def embed(self) -> None:\n        \"\"\"\n        Embeds the documents using the Cohere API.\n        \"\"\"\n        print(\"Embedding documents...\")\n\n        batch_size = 90\n        self.docs_len = len(self.docs)\n\n        for i in range(0, self.docs_len, batch_size):\n            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n            texts = [item[\"text\"] for item in batch]\n            docs_embs_batch = co.embed(\n                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n            ).embeddings\n            self.docs_embs.extend(docs_embs_batch)\n\n    def index(self) -> None:\n        \"\"\"\n        Indexes the documents for efficient retrieval.\n        \"\"\"\n        print(\"Indexing documents...\")\n\n        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n\n        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n\n    def retrieve(self, query: str) -> List[Dict[str, str]]:\n        \"\"\"\n        Retrieves documents based on the given query.\n\n        Parameters:\n        query (str): The query to retrieve documents for.\n\n        Returns:\n        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents, with 'title', 'text', and 'url' keys.\n        \"\"\"\n        docs_retrieved = []\n        query_emb = co.embed(\n            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n        ).embeddings\n\n        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n\n        docs_to_rerank = []\n        for doc_id in doc_ids:\n            docs_to_rerank.append(self.docs[doc_id][\"text\"])\n\n        rerank_results = co.rerank(\n            query=query,\n            documents=docs_to_rerank,\n            top_n=self.rerank_top_k,\n            model=\"rerank-english-v2.0\",\n        )\n\n        doc_ids_reranked = []\n        for result in rerank_results:\n            doc_ids_reranked.append(doc_ids[result.index])\n\n        for doc_id in doc_ids_reranked:\n            docs_retrieved.append(\n                {\n                    \"title\": self.docs[doc_id][\"title\"],\n                    \"text\": self.docs[doc_id][\"text\"],\n                    \"url\": self.docs[doc_id][\"url\"],\n                }\n            )\n\n        return docs_retrieved","metadata":{"id":"1cJasXvgZy7O","outputId":"e1f12a5d-cfca-407d-806f-103efbb57463","execution":{"iopub.status.busy":"2023-11-26T20:49:12.675813Z","iopub.execute_input":"2023-11-26T20:49:12.676580Z","iopub.status.idle":"2023-11-26T20:49:12.700107Z","shell.execute_reply.started":"2023-11-26T20:49:12.676539Z","shell.execute_reply":"2023-11-26T20:49:12.699021Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n  <style>\n    pre {\n        white-space: pre-wrap;\n    }\n  </style>\n  "},"metadata":{}}]},{"cell_type":"markdown","source":"### Chatbot component","metadata":{"id":"T7waoA07Zy7R"}},{"cell_type":"code","source":"class Chatbot:\n    \"\"\"\n    A class representing a chatbot.\n\n    Parameters:\n    docs (Documents): An instance of the Documents class representing the collection of documents.\n\n    Attributes:\n    conversation_id (str): The unique ID for the conversation.\n    docs (Documents): An instance of the Documents class representing the collection of documents.\n\n    Methods:\n    generate_response(message): Generates a response to the user's message.\n    retrieve_docs(response): Retrieves documents based on the search queries in the response.\n\n    \"\"\"\n\n    def __init__(self, docs: Documents):\n        self.docs = docs\n        self.conversation_id = str(uuid.uuid4())\n\n    def generate_response(self, message: str):\n        \"\"\"\n        Generates a response to the user's message.\n\n        Parameters:\n        message (str): The user's message.\n\n        Yields:\n        Event: A response event generated by the chatbot.\n\n        Returns:\n        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n\n        \"\"\"\n        # Generate search queries (if any)\n        response = co.chat(message=message, search_queries_only=True)\n\n        # If there are search queries, retrieve documents and respond\n        if response.search_queries:\n            print(\"Retrieving information...\")\n\n            documents = self.retrieve_docs(response)\n\n            response = co.chat(\n                message=message,\n                documents=documents,\n                conversation_id=self.conversation_id,\n                stream=True,\n            )\n            for event in response:\n                yield event\n\n        # If there is no search query, directly respond\n        else:\n            response = co.chat(\n                message=message,\n                conversation_id=self.conversation_id,\n                stream=True\n            )\n            for event in response:\n                yield event\n\n    def retrieve_docs(self, response) -> List[Dict[str, str]]:\n        \"\"\"\n        Retrieves documents based on the search queries in the response.\n\n        Parameters:\n        response: The response object containing search queries.\n\n        Returns:\n        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n\n        \"\"\"\n        # Get the query(s)\n        queries = []\n        for search_query in response.search_queries:\n            queries.append(search_query[\"text\"])\n\n        # Retrieve documents for each query\n        retrieved_docs = []\n        for query in queries:\n            retrieved_docs.extend(self.docs.retrieve(query))\n\n        # # Uncomment this code block to display the chatbot's retrieved documents\n        # print(\"DOCUMENTS RETRIEVED:\")\n        # for idx, doc in enumerate(retrieved_docs):\n        #     print(f\"doc_{idx}: {doc}\")\n        # print(\"\\n\")\n\n        return retrieved_docs","metadata":{"id":"Io6gx6ZeZy7S","outputId":"890ed551-d3e9-4f3d-a523-4df3cca4aa1a","execution":{"iopub.status.busy":"2023-11-26T20:49:16.604617Z","iopub.execute_input":"2023-11-26T20:49:16.604986Z","iopub.status.idle":"2023-11-26T20:49:16.617954Z","shell.execute_reply.started":"2023-11-26T20:49:16.604957Z","shell.execute_reply":"2023-11-26T20:49:16.616967Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n  <style>\n    pre {\n        white-space: pre-wrap;\n    }\n  </style>\n  "},"metadata":{}}]},{"cell_type":"markdown","source":"### App component","metadata":{"id":"2iULnxosZy7T"}},{"cell_type":"code","source":"class App:\n    def __init__(self, chatbot: Chatbot):\n        \"\"\"\n        Initializes an instance of the App class.\n\n        Parameters:\n        chatbot (Chatbot): An instance of the Chatbot class.\n\n        \"\"\"\n        self.chatbot = chatbot\n\n    def run(self):\n        \"\"\"\n        Runs the chatbot application.\n\n        \"\"\"\n        while True:\n            # Get the user message\n            message = input(\"User: \")\n\n            # Typing \"quit\" ends the conversation\n            if message.lower() == \"quit\":\n                print(\"Ending chat.\")\n                break\n            else:\n                print(f\"User: {message}\")\n\n            # Get the chatbot response\n            response = self.chatbot.generate_response(message)\n\n            # Print the chatbot response\n            print(\"Chatbot:\")\n            flag = False\n            for event in response:\n                # Text\n                if event.event_type == \"text-generation\":\n                    print(event.text, end=\"\")\n\n                # Citations\n                if event.event_type == \"citation-generation\":\n                    if not flag:\n                        print(\"\\n\\nCITATIONS:\")\n                        flag = True\n                    print(event.citations)\n\n            print(f\"\\n{'-'*100}\\n\")","metadata":{"id":"pYIQnNyBZy7T","outputId":"0a676d38-aaba-4f87-9ff5-6b59d8ee2939","execution":{"iopub.status.busy":"2023-11-26T20:49:20.058124Z","iopub.execute_input":"2023-11-26T20:49:20.059043Z","iopub.status.idle":"2023-11-26T20:49:20.068569Z","shell.execute_reply.started":"2023-11-26T20:49:20.059004Z","shell.execute_reply":"2023-11-26T20:49:20.067623Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n  <style>\n    pre {\n        white-space: pre-wrap;\n    }\n  </style>\n  "},"metadata":{}}]},{"cell_type":"markdown","source":"### Define the documents","metadata":{"id":"jtkg-d9sZy7U"}},{"cell_type":"code","source":"# Define the sources for the documents\n# As an example, we'll use LLM University's Module 1: What are Large Language Models?\n# https://docs.cohere.com/docs/intro-large-language-models\n\n\nsources = [\n    {\n        \"title\": \"Text Line Segmentation of Historical Documents: a Survey\",\n        \"url\": \"https://arxiv.org/abs/0704.1267\"\n    },\n    {\n        \"title\": \"Riemannian level-set methods for tensor-valued data\",\n        \"url\": \"https://arxiv.org/abs/0705.0214\"\n    },\n    {\n        \"title\": \"Multiresolution Approximation of Polygonal Curves in Linear Complexity\",\n        \"url\": \"https://arxiv.org/abs/0705.0449\"\n    },\n    {\n        \"title\": \"Medical Image Segmentation and Localization using Deformable Templates\",\n        \"url\": \"https://arxiv.org/abs/0705.0781\"\n    },\n    {\n        \"title\": \"Enhancement of Noisy Planar Nuclear Medicine Images using Mean Field\\n  Annealing\",\n        \"url\": \"https://arxiv.org/abs/0705.0828\"\n    },\n    {\n        \"title\": \"An Independent Evaluation of Subspace Face Recognition Algorithms\",\n        \"url\": \"https://arxiv.org/abs/0705.0952\"\n    },\n    {\n        \"title\": \"MI image registration using prior knowledge\",\n        \"url\": \"https://arxiv.org/abs/0705.3593\"\n    },\n    {\n        \"title\": \"Automatic Detection of Pulmonary Embolism using Computational\\n  Intelligence\",\n        \"url\": \"https://arxiv.org/abs/0706.0300\"\n    },\n    {\n        \"title\": \"Variational local structure estimation for image super-resolution\",\n        \"url\": \"https://arxiv.org/abs/0709.1771\"\n    },\n    {\n        \"title\": \"Bandwidth selection for kernel estimation in mixed multi-dimensional\\n  spaces\",\n        \"url\": \"https://arxiv.org/abs/0709.1920\"\n    },\n    {\n        \"title\": \"Supervised learning on graphs of spatio-temporal similarity in satellite\\n  image sequences\",\n        \"url\": \"https://arxiv.org/abs/0709.3013\"\n    },\n    {\n        \"title\": \"Graph rigidity, Cyclic Belief Propagation and Point Pattern Matching\",\n        \"url\": \"https://arxiv.org/abs/0710.0043\"\n    },\n    {\n        \"title\": \"High-Order Nonparametric Belief-Propagation for Fast Image Inpainting\",\n        \"url\": \"https://arxiv.org/abs/0710.0243\"\n    },\n    {\n        \"title\": \"An Affinity Propagation Based method for Vector Quantization Codebook\\n  Design\",\n        \"url\": \"https://arxiv.org/abs/0710.2037\"\n    },\n    {\n        \"title\": \"Comparison and Combination of State-of-the-art Techniques for\\n  Handwritten Character Recognition: Topping the MNIST Benchmark\",\n        \"url\": \"https://arxiv.org/abs/0710.2231\"\n    },\n    {\n        \"title\": \"Learning Similarity for Character Recognition and 3D Object Recognition\",\n        \"url\": \"https://arxiv.org/abs/0712.0131\"\n    },\n    {\n        \"title\": \"Learning View Generalization Functions\",\n        \"url\": \"https://arxiv.org/abs/0712.0136\"\n    },\n    {\n        \"title\": \"View Based Methods can achieve Bayes-Optimal 3D Recognition\",\n        \"url\": \"https://arxiv.org/abs/0712.0137\"\n    },\n    {\n        \"title\": \"Hierarchy construction schemes within the Scale set framework\",\n        \"url\": \"https://arxiv.org/abs/0712.1878\"\n    },\n    {\n        \"title\": \"A Class of LULU Operators on Multi-Dimensional Arrays\",\n        \"url\": \"https://arxiv.org/abs/0712.2923\"\n    },\n    {\n        \"title\": \"A Fast Hierarchical Multilevel Image Segmentation Method using Unbiased\\n  Estimators\",\n        \"url\": \"https://arxiv.org/abs/0712.4015\"\n    },\n    {\n        \"title\": \"Automatic Text Area Segmentation in Natural Images\",\n        \"url\": \"https://arxiv.org/abs/0801.4807\"\n    },\n    {\n        \"title\": \"Wavelet and Curvelet Moments for Image Classification: Application to\\n  Aggregate Mixture Grading\",\n        \"url\": \"https://arxiv.org/abs/0802.3528\"\n    },\n    {\n        \"title\": \"Spatio-activity based object detection\",\n        \"url\": \"https://arxiv.org/abs/0803.1586\"\n    },\n    {\n        \"title\": \"Using Spatially Varying Pixels Exposures and Bayer-covered Photosensors\\n  for High Dynamic Range Imaging\",\n        \"url\": \"https://arxiv.org/abs/0803.2812\"\n    },\n    {\n        \"title\": \"Linear Time Recognition Algorithms for Topological Invariants in 3D\",\n        \"url\": \"https://arxiv.org/abs/0804.1982\"\n    },\n    {\n        \"title\": \"A New Algorithm for Interactive Structural Image Segmentation\",\n        \"url\": \"https://arxiv.org/abs/0805.1854\"\n    },\n    {\n        \"title\": \"A multilateral filtering method applied to airplane runway image\",\n        \"url\": \"https://arxiv.org/abs/0805.2324\"\n    },\n    {\n        \"title\": \"Increasing Linear Dynamic Range of Commercial Digital Photocamera Used\\n  in Imaging Systems with Optical Coding\",\n        \"url\": \"https://arxiv.org/abs/0805.2690\"\n    },\n    {\n        \"title\": \"Statistical region-based active contours with exponential family\\n  observations\",\n        \"url\": \"https://arxiv.org/abs/0805.3217\"\n    },\n    {\n        \"title\": \"Region-based active contour with noise and shape priors\",\n        \"url\": \"https://arxiv.org/abs/0805.3218\"\n    },\n    {\n        \"title\": \"DimReduction - Interactive Graphic Environment for Dimensionality\\n  Reduction\",\n        \"url\": \"https://arxiv.org/abs/0805.3964\"\n    },\n    {\n        \"title\": \"Directional Cross Diamond Search Algorithm for Fast Block Motion\\n  Estimation\",\n        \"url\": \"https://arxiv.org/abs/0806.0689\"\n    },\n    {\n        \"title\": \"Fast Wavelet-Based Visual Classification\",\n        \"url\": \"https://arxiv.org/abs/0806.1446\"\n    },\n    {\n        \"title\": \"Classification of curves in 2D and 3D via affine integral signatures\",\n        \"url\": \"https://arxiv.org/abs/0806.1984\"\n    },\n    {\n        \"title\": \"Conceptualization of seeded region growing by pixels aggregation. Part\\n  1: the framework\",\n        \"url\": \"https://arxiv.org/abs/0806.3885\"\n    },\n    {\n        \"title\": \"Conceptualization of seeded region growing by pixels aggregation. Part\\n  2: how to localize a final partition invariant about the seeded region\\n  initialisation order\",\n        \"url\": \"https://arxiv.org/abs/0806.3887\"\n    },\n    {\n        \"title\": \"Conceptualization of seeded region growing by pixels aggregation. Part\\n  3: a wide range of algorithms\",\n        \"url\": \"https://arxiv.org/abs/0806.3928\"\n    },\n    {\n        \"title\": \"Conceptualization of seeded region growing by pixels aggregation. Part\\n  4: Simple, generic and robust extraction of grains in granular materials\\n  obtained by X-ray tomography\",\n        \"url\": \"https://arxiv.org/abs/0806.3939\"\n    },\n    {\n        \"title\": \"The Five Points Pose Problem : A New and Accurate Solution Adapted to\\n  any Geometric Configuration\",\n        \"url\": \"https://arxiv.org/abs/0807.2047\"\n    },\n    {\n        \"title\": \"An image processing analysis of skin textures\",\n        \"url\": \"https://arxiv.org/abs/0807.4701\"\n    },\n    {\n        \"title\": \"Higher Order Moments Generation by Mellin Transform for Compound Models\\n  of Clutter\",\n        \"url\": \"https://arxiv.org/abs/0808.2227\"\n    },\n    {\n        \"title\": \"Automatic Identification and Data Extraction from 2-Dimensional Plots in\\n  Digital Documents\",\n        \"url\": \"https://arxiv.org/abs/0809.1802\"\n    },\n    {\n        \"title\": \"Supervised Dictionary Learning\",\n        \"url\": \"https://arxiv.org/abs/0809.3083\"\n    },\n    {\n        \"title\": \"Modeling and Control with Local Linearizing Nadaraya Watson Regression\",\n        \"url\": \"https://arxiv.org/abs/0809.3690\"\n    },\n    {\n        \"title\": \"Hierarchical Bag of Paths for Kernel Based Shape Classification\",\n        \"url\": \"https://arxiv.org/abs/0810.3579\"\n    },\n    {\n        \"title\": \"Camera distortion self-calibration using the plumb-line constraint and\\n  minimal Hough entropy\",\n        \"url\": \"https://arxiv.org/abs/0810.4426\"\n    },\n    {\n        \"title\": \"Graph-based classification of multiple observation sets\",\n        \"url\": \"https://arxiv.org/abs/0810.4617\"\n    },\n    {\n        \"title\": \"3D Face Recognition with Sparse Spherical Representations\",\n        \"url\": \"https://arxiv.org/abs/0810.5325\"\n    },\n    {\n        \"title\": \"Mapping Images with the Coherence Length Diagrams\",\n        \"url\": \"https://arxiv.org/abs/0811.4699\"\n    },\n    {\n        \"title\": \"Obtaining Depth Maps From Color Images By Region Based Stereo Matching\\n  Algorithms\",\n        \"url\": \"https://arxiv.org/abs/0812.1340\"\n    },\n    {\n        \"title\": \"Sparse Component Analysis (SCA) in Random-valued and Salt and Pepper\\n  Noise Removal\",\n        \"url\": \"https://arxiv.org/abs/0812.2892\"\n    },\n    {\n        \"title\": \"A Keygraph Classification Framework for Real-Time Object Detection\",\n        \"url\": \"https://arxiv.org/abs/0901.4953\"\n    },\n    {\n        \"title\": \"Using SLP Neural Network to Persian Handwritten Digits Recognition\",\n        \"url\": \"https://arxiv.org/abs/0902.2788\"\n    },\n    {\n        \"title\": \"Dipole and Quadrupole Moments in Image Processing\",\n        \"url\": \"https://arxiv.org/abs/0902.4073\"\n    },\n    {\n        \"title\": \"Dipole Vectors in Images Processing\",\n        \"url\": \"https://arxiv.org/abs/0902.4663\"\n    },\n    {\n        \"title\": \"Recognition of Regular Shapes in Satelite Images\",\n        \"url\": \"https://arxiv.org/abs/0903.0134\"\n    },\n    {\n        \"title\": \"Real-time Texture Error Detection\",\n        \"url\": \"https://arxiv.org/abs/0903.0538\"\n    },\n    {\n        \"title\": \"Digital Restoration of Ancient Papyri\",\n        \"url\": \"https://arxiv.org/abs/0903.5045\"\n    },\n    {\n        \"title\": \"Color Dipole Moments for Edge Detection\",\n        \"url\": \"https://arxiv.org/abs/0904.0962\"\n    },\n    {\n        \"title\": \"On the closed-form solution of the rotation matrix arising in computer\\n  vision problems\",\n        \"url\": \"https://arxiv.org/abs/0904.1613\"\n    },\n    {\n        \"title\": \"Point-Set Registration: Coherent Point Drift\",\n        \"url\": \"https://arxiv.org/abs/0905.2635\"\n    },\n    {\n        \"title\": \"Colorization of Natural Images via L1 Optimization\",\n        \"url\": \"https://arxiv.org/abs/0905.2924\"\n    },\n    {\n        \"title\": \"A statistical learning approach to color demosaicing\",\n        \"url\": \"https://arxiv.org/abs/0905.2958\"\n    },\n    {\n        \"title\": \"A New Solution to the Relative Orientation Problem using only 3 Points\\n  and the Vertical Direction\",\n        \"url\": \"https://arxiv.org/abs/0905.3964\"\n    },\n    {\n        \"title\": \"Segmentation of Facial Expressions Using Semi-Definite Programming and\\n  Generalized Principal Component Analysis\",\n        \"url\": \"https://arxiv.org/abs/0906.1763\"\n    },\n    {\n        \"title\": \"Combinatorial pyramids and discrete geometry for energy-minimizing\\n  segmentation\",\n        \"url\": \"https://arxiv.org/abs/0906.2770\"\n    },\n    {\n        \"title\": \"Deformable Model with a Complexity Independent from Image Resolution\",\n        \"url\": \"https://arxiv.org/abs/0906.3068\"\n    },\n    {\n        \"title\": \"Adaptive Regularization of Ill-Posed Problems: Application to Non-rigid\\n  Image Registration\",\n        \"url\": \"https://arxiv.org/abs/0906.3323\"\n    },\n    {\n        \"title\": \"Automatic Defect Detection and Classification Technique from Image: A\\n  Special Case Using Ceramic Tiles\",\n        \"url\": \"https://arxiv.org/abs/0906.3770\"\n    },\n    {\n        \"title\": \"Automatic Spatially-Adaptive Balancing of Energy Terms for Image\\n  Segmentation\",\n        \"url\": \"https://arxiv.org/abs/0906.4131\"\n    },\n    {\n        \"title\": \"Efficient IRIS Recognition through Improvement of Feature Extraction and\\n  subset Selection\",\n        \"url\": \"https://arxiv.org/abs/0906.4789\"\n    },\n    {\n        \"title\": \"A new approach for digit recognition based on hand gesture analysis\",\n        \"url\": \"https://arxiv.org/abs/0906.5039\"\n    },\n    {\n        \"title\": \"Multi-Label MRF Optimization via Least Squares s-t Cuts\",\n        \"url\": \"https://arxiv.org/abs/0907.0204\"\n    },\n    {\n        \"title\": \"An Iterative Fingerprint Enhancement Algorithm Based on Accurate\\n  Determination of Orientation Flow\",\n        \"url\": \"https://arxiv.org/abs/0907.0288\"\n    },\n    {\n        \"title\": \"Bounding the Probability of Error for High Precision Recognition\",\n        \"url\": \"https://arxiv.org/abs/0907.0418\"\n    },\n    {\n        \"title\": \"Augmenting Light Field to model Wave Optics effects\",\n        \"url\": \"https://arxiv.org/abs/0907.1545\"\n    },\n    {\n        \"title\": \"Multiresolution Elastic Medical Image Registration in Standard Intensity\\n  Scale\",\n        \"url\": \"https://arxiv.org/abs/0907.2075\"\n    },\n    {\n        \"title\": \"Registration of Standardized Histological Images in Feature Space\",\n        \"url\": \"https://arxiv.org/abs/0907.3209\"\n    },\n    {\n        \"title\": \"Fully Automatic 3D Reconstruction of Histological Images\",\n        \"url\": \"https://arxiv.org/abs/0907.3215\"\n    },\n    {\n        \"title\": \"Parallel AdaBoost Algorithm for Gabor Wavelet Selection in Face\\n  Recognition\",\n        \"url\": \"https://arxiv.org/abs/0907.3218\"\n    },\n    {\n        \"title\": \"Learning Object Location Predictors with Boosting and Grammar-Guided\\n  Feature Extraction\",\n        \"url\": \"https://arxiv.org/abs/0907.4354\"\n    },\n    {\n        \"title\": \"Automatic local Gabor Features extraction for face recognition\",\n        \"url\": \"https://arxiv.org/abs/0907.4984\"\n    },\n    {\n        \"title\": \"Multiple pattern classification by sparse subspace decomposition\",\n        \"url\": \"https://arxiv.org/abs/0907.5321\"\n    },\n    {\n        \"title\": \"Segmentation for radar images based on active contour\",\n        \"url\": \"https://arxiv.org/abs/0908.1369\"\n    },\n    {\n        \"title\": \"A dyadic solution of relative pose problems\",\n        \"url\": \"https://arxiv.org/abs/0908.1919\"\n    },\n    {\n        \"title\": \"Handwritten Farsi Character Recognition using Artificial Neural Network\",\n        \"url\": \"https://arxiv.org/abs/0908.4386\"\n    },\n    {\n        \"title\": \"Scale-Based Gaussian Coverings: Combining Intra and Inter Mixture Models\\n  in Image Segmentation\",\n        \"url\": \"https://arxiv.org/abs/0909.0481\"\n    },\n    {\n        \"title\": \"Kernel Spectral Curvature Clustering (KSCC)\",\n        \"url\": \"https://arxiv.org/abs/0909.1605\"\n    },\n    {\n        \"title\": \"Motion Segmentation by SCC on the Hopkins 155 Database\",\n        \"url\": \"https://arxiv.org/abs/0909.1608\"\n    },\n    {\n        \"title\": \"A Method for Extraction and Recognition of Isolated License Plate\\n  Characters\",\n        \"url\": \"https://arxiv.org/abs/0909.3911\"\n    },\n    {\n        \"title\": \"Information tracking approach to segmentation of ultrasound imagery of\\n  prostate\",\n        \"url\": \"https://arxiv.org/abs/0909.5458\"\n    },\n    {\n        \"title\": \"Iterative Shrinkage Approach to Restoration of Optical Imagery\",\n        \"url\": \"https://arxiv.org/abs/0909.5460\"\n    },\n    {\n        \"title\": \"Modular Traffic Sign Recognition applied to on-vehicle real-time visual\\n  detection of American and European speed limit signs\",\n        \"url\": \"https://arxiv.org/abs/0910.1295\"\n    },\n    {\n        \"title\": \"3D/2D Registration of Mapping Catheter Images for Arrhythmia\\n  Interventional Assistance\",\n        \"url\": \"https://arxiv.org/abs/0910.1844\"\n    },\n    {\n        \"title\": \"Color Image Clustering using Block Truncation Algorithm\",\n        \"url\": \"https://arxiv.org/abs/0910.1849\"\n    },\n    {\n        \"title\": \"Fractional differentiation based image processing\",\n        \"url\": \"https://arxiv.org/abs/0910.2381\"\n    },\n    {\n        \"title\": \"Behavior Subtraction\",\n        \"url\": \"https://arxiv.org/abs/0910.2917\"\n    },\n    {\n        \"title\": \"A $p$-adic RanSaC algorithm for stereo vision using Hensel lifting\",\n        \"url\": \"https://arxiv.org/abs/0910.4839\"\n    },\n    {\n        \"title\": \"An Iterative Shrinkage Approach to Total-Variation Image Restoration\",\n        \"url\": \"https://arxiv.org/abs/0910.5002\"\n    }\n]","metadata":{"id":"-E8cax9TZy7U","outputId":"4d6962ea-371f-42ff-c9aa-1651993f3b33","execution":{"iopub.status.busy":"2023-11-26T20:49:23.499271Z","iopub.execute_input":"2023-11-26T20:49:23.499683Z","iopub.status.idle":"2023-11-26T20:49:23.537175Z","shell.execute_reply.started":"2023-11-26T20:49:23.499650Z","shell.execute_reply":"2023-11-26T20:49:23.536260Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n  <style>\n    pre {\n        white-space: pre-wrap;\n    }\n  </style>\n  "},"metadata":{}}]},{"cell_type":"markdown","source":"### Process the documents","metadata":{"id":"o2o6d3X9Zy7V"}},{"cell_type":"code","source":"# Create an instance of the Documents class with the given sources\ndocuments = Documents(sources)","metadata":{"id":"KlEv9cfZZy7X","outputId":"adb0546f-050b-4107-943d-10402b54674c","execution":{"iopub.status.busy":"2023-11-26T20:49:39.855885Z","iopub.execute_input":"2023-11-26T20:49:39.856588Z","iopub.status.idle":"2023-11-26T20:50:26.942932Z","shell.execute_reply.started":"2023-11-26T20:49:39.856557Z","shell.execute_reply":"2023-11-26T20:50:26.941782Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n  <style>\n    pre {\n        white-space: pre-wrap;\n    }\n  </style>\n  "},"metadata":{}},{"name":"stdout","text":"Loading documents...\nEmbedding documents...\nIndexing documents...\nIndexing complete with 1102 documents.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Run the chatbot","metadata":{"id":"a90WKyqwZy7Y"}},{"cell_type":"code","source":"# Create an instance of the Chatbot class with the Documents instance\nchatbot = Chatbot(documents)\n\n# Create an instance of the App class with the Chatbot instance\napp = App(chatbot)\n\n# Run the chatbot\napp.run()","metadata":{"id":"FZGIV8F2Zy7Y","execution":{"iopub.status.busy":"2023-11-26T20:50:29.576153Z","iopub.execute_input":"2023-11-26T20:50:29.576509Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n  <style>\n    pre {\n        white-space: pre-wrap;\n    }\n  </style>\n  "},"metadata":{}},{"output_type":"stream","name":"stdin","text":"User:  Hi\n"},{"name":"stdout","text":"User: Hi\nChatbot:\nHi there, how can I help you ? Today's date is Sunday, November 26th, 2023, would you like me to help you with something in relation to this date? \n\nAlternatively, you can ask me anything and I will try my best to assist you!\n----------------------------------------------------------------------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  give me some datasets of Arrhythmia\n"},{"name":"stdout","text":"User: give me some datasets of Arrhythmia\nChatbot:\nRetrieving information...\nI couldn't find any specific datasets of Arrhythmia, but I did find some research papers that may be of interest to you. Would you like me to summarise some of these papers for you? \n\nAlternatively, you can ask me for datasets of Arrhythmia specifically and I will notify you as soon as I find some.\n----------------------------------------------------------------------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  what is segmentation?\n"},{"name":"stdout","text":"User: what is segmentation?\nChatbot:\nRetrieving information...\nSegmentation is a process of dividing an image or a graph into distinct regions, which are meaningful and easier to analyse. It is a typical preliminary step for many computer vision tasks. Various energy minimisation schemes such as the deformation graph and schemes based on combinatorial pyramids are utilised for the segmentation process. Would you like me to go into more detail about any of the segmentation techniques?\n\nCITATIONS:\n[{'start': 29, 'end': 79, 'text': 'dividing an image or a graph into distinct regions', 'document_ids': ['doc_0', 'doc_1', 'doc_2']}]\n[{'start': 238, 'end': 255, 'text': 'deformation graph', 'document_ids': ['doc_0']}]\n[{'start': 277, 'end': 299, 'text': 'combinatorial pyramids', 'document_ids': ['doc_2']}]\n\n----------------------------------------------------------------------------------------------------\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  AdaBoost Algorithm\n"},{"name":"stdout","text":"User: AdaBoost Algorithm\nChatbot:\nRetrieving information...\nThe AdaBoost algorithm is a boosting technique used to learn a classifier on data and optimise the method of converting the pixel classifications into high-quality sets of (x, y) locations. The original AdaBoost takes into account the spatially correlated nature of the data.\n\nThere is also a variant called Parallel AdaBoost, which incorporates the use of Gabor wavelets and mutual information to select effective image features for use in face recognition. This variant uses Parallel Boosting methods to optimise the selection process based not only on classification accuracy but also on efficiency. \n\nWould you like me to go into more detail about any of the AdaBoost variants?\n\nCITATIONS:\n[{'start': 28, 'end': 46, 'text': 'boosting technique', 'document_ids': ['doc_1', 'doc_5']}]\n[{'start': 55, 'end': 81, 'text': 'learn a classifier on data', 'document_ids': ['doc_1', 'doc_5']}]\n[{'start': 86, 'end': 145, 'text': 'optimise the method of converting the pixel classifications', 'document_ids': ['doc_1', 'doc_5']}]\n[{'start': 151, 'end': 189, 'text': 'high-quality sets of (x, y) locations.', 'document_ids': ['doc_1', 'doc_5']}]\n[{'start': 212, 'end': 275, 'text': 'takes into account the spatially correlated nature of the data.', 'document_ids': ['doc_1', 'doc_5']}]\n[{'start': 293, 'end': 325, 'text': 'variant called Parallel AdaBoost', 'document_ids': ['doc_0', 'doc_3', 'doc_4']}]\n[{'start': 357, 'end': 371, 'text': 'Gabor wavelets', 'document_ids': ['doc_0', 'doc_3', 'doc_4']}]\n[{'start': 376, 'end': 394, 'text': 'mutual information', 'document_ids': ['doc_0']}]\n[{'start': 398, 'end': 429, 'text': 'select effective image features', 'document_ids': ['doc_0']}]\n[{'start': 441, 'end': 458, 'text': 'face recognition.', 'document_ids': ['doc_0', 'doc_3', 'doc_4']}]\n[{'start': 472, 'end': 502, 'text': 'uses Parallel Boosting methods', 'document_ids': ['doc_0', 'doc_3', 'doc_4']}]\n[{'start': 506, 'end': 536, 'text': 'optimise the selection process', 'document_ids': ['doc_0']}]\n[{'start': 543, 'end': 578, 'text': 'not only on classification accuracy', 'document_ids': ['doc_0']}]\n[{'start': 591, 'end': 602, 'text': 'efficiency.', 'document_ids': ['doc_0']}]\n\n----------------------------------------------------------------------------------------------------\n\n","output_type":"stream"}]}]}